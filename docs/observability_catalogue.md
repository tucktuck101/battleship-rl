# Observability Catalogue

Source of truth for Battleship RL signals (metrics, traces, logs, etc.).
Populate each row as we formalize new telemetry.

## Column Schema

| Column Name | Column Data Type | Column Description |
|-------------|------------------|--------------------|
| SLO Group / Domain | string | High-level category the SLO belongs to (Learning, Performance, Stability, Exploration, Environment, Observability Pipeline). |
| SLO ID | string | Short unique identifier for the SLO (e.g. `SLO-LRN-001`). |
| SLO Name | string | Human-readable name of the SLO. |
| SLO Objective / Target | string | The reliability goal or threshold (e.g. “≥ 60% win rate over last 1000 episodes”). |
| SLO Window / Error Budget Notes | string | Measurement window and notes on error budget handling. |
| SLI Name | string | Name of the Service Level Indicator used to measure the SLO. |
| SLI Definition | string | Plain-language description of what the SLI measures. |
| SLI Formula (Logical) | string | Backend-agnostic conceptual calculation of the SLI. |
| SLI Backend (Authoritative) | enum (Prometheus, Loki, Tempo, multi-value) | Backend(s) considered authoritative for computing the SLI. |
| Friendly Name | string | Human-friendly name of the telemetry signal. |
| Signal Type | enum (metric, log, trace) | Type of telemetry object emitted. |
| Subtype | enum (counter, gauge, histogram, span, log-event, etc.) | Specific metric or signal subtype. |
| Canonical Name | string | Actual exported metric/log/span name. |
| Description | string | Description of what the signal represents. |
| Attributes / Labels | list<string> | Label keys applied to the signal (e.g. `run_id`, `episode`, `agent_id`). |
| Cardinality Notes | string | Expected cardinality and constraints or considerations. |
| Prometheus? | boolean (Y/N) | Whether this signal is stored and queryable in Prometheus. |
| Prometheus Query | string | Example PromQL query used to validate or compute SLI. Empty if Prometheus? = No. |
| Loki? | boolean (Y/N) | Whether this signal is stored and queryable in Loki. |
| Loki Query | string | Example LogQL query for validation or analysis. Empty if Loki? = No. |
| Tempo? | boolean (Y/N) | Whether this signal is stored and queryable in Tempo. |
| Tempo Query | string | Example Tempo search or filter query. Empty if Tempo? = No. |
| OTLP Export Path / Env Vars | string | How the signal is exported to the collector (env vars, endpoint, exporter config). |
| Collector Receiver | enum (otlp/grpc, otlp/http, etc.) | Collector receiver that ingests this signal. |
| Component | string | Application component responsible for emitting the signal (trainer, engine, agent, UI, collector). |
| File Name | string | Source file where this signal is implemented. |
| Status | enum (Planned, Implemented, Validated, Partial, Deprecated) | Current implementation state of the signal. |

## Example Row

| SLO Group / Domain | SLO ID | SLO Name | SLO Objective / Target | SLO Window / Error Budget Notes | SLI Name | SLI Definition | SLI Formula (Logical) | SLI Backend (Authoritative) | Friendly Name | Signal Type | Subtype | Canonical Name | Description | Attributes / Labels | Cardinality Notes | Prometheus? | Prometheus Query | Loki? | Loki Query | Tempo? | Tempo Query | OTLP Export Path / Env Vars | Collector Receiver | Component | File Name | Status |
|--------------------|--------|----------|-------------------------|----------------------------------|-----------|----------------|------------------------|------------------------------|---------------|-------------|---------|----------------|-------------|----------------------|-------------------|-------------|-------------------|--------|------------|---------|-------------|------------------------------|--------------------|-----------|-----------|--------|
| Learning Progress | SLO-LRN-001 | Episode Win Rate | After the first 2,000 episodes, the win rate averaged over the most recent 1,000 episodes must be ≥60%. | Ignore the first 2,000 episodes per run; sliding 1,000-episode windows with 40% error budget. | Episode Win Rate SLI | Measures the proportion of episodes ending in an agent win. | sum(win) / count(win) for last 1,000 episodes. | Prometheus | Episode Win Flag | Metric | Counter | `battleship_episode_win` | Emits 1 when the agent wins the episode, otherwise 0. | `run_id`,`episode`,`agent_id`,`opponent_type` | One sample per complete episode per run. | Y | sum_over_time(battleship_episode_win{run_id="$run"}[1000episodes]) / count_over_time(battleship_episode_win{run_id="$run"}[1000episodes]) | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |


## Catalogue

| SLO Group / Domain | SLO ID | SLO Name | SLO Objective / Target | SLO Window / Error Budget Notes | SLI Name | SLI Definition | SLI Formula (Logical) | SLI Backend (Authoritative) | Friendly Name | Signal Type | Subtype | Canonical Name | Description | Attributes / Labels | Cardinality Notes | Prometheus? | Prometheus Query | Loki? | Loki Query | Tempo? | Tempo Query | OTLP Export Path / Env Vars | Collector Receiver | Component | File Name | Status |
|--------------------|--------|----------|-------------------------|----------------------------------|-----------|----------------|------------------------|------------------------------|---------------|-------------|---------|----------------|-------------|----------------------|-------------------|-------------|-------------------|--------|------------|---------|-------------|------------------------------|--------------------|-----------|-----------|--------|
| Learning Progress | SLO-LRN-002 | Episode Reward Trend | Smoothed mean reward must not drop by >10% between consecutive 500-episode windows and must increase ≥20% over the first 2,000 episodes. | Rolling 500-episode windows per run with an additional ramp-up check on the first 2,000 episodes. | Episode Reward Trend SLI | Compares rolling averages of episode reward to detect stagnation or negative learning. | trend = avg_reward_n / avg_reward_n-1; initial_gain >= 0.20. | Prometheus | Episode Reward Sum | Metric | Gauge | `battleship_episode_reward_sum` | Total reward aggregated per episode for trend comparison windows. | `run_id`,`episode`,`opponent_type` | One value per episode per run. | Y | avg_over_time(battleship_episode_reward_sum{run_id="$run"}[500episodes]) | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Learning Progress | SLO-LRN-001 | Episode Win Rate | After the first 2,000 episodes, the win rate averaged over the most recent 1,000 episodes must be ≥60%. | Ignore the first 2,000 episodes per run; sliding 1,000-episode windows with 40% error budget. | Episode Win Rate SLI | Measures the proportion of episodes ending in an agent win. | sum(win) / count(win) for last 1,000 episodes. | Prometheus | Episode Win Flag | Metric | Counter | `battleship_episode_win` | Emits 1 when the agent wins the episode, otherwise 0. | `run_id`,`episode`,`agent_id`,`opponent_type` | One sample per complete episode per run. | Y | sum_over_time(battleship_episode_win{run_id="$run"}[1000episodes]) / count_over_time(battleship_episode_win{run_id="$run"}[1000episodes]) | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Learning Progress | SLO-LRN-003 | Steps-to-Outcome | Avg steps to win ≤ 0.85 × baseline and steps-to-loss must be non-increasing over the last 1,000 episodes. | Sliding 1,000-episode cohorts per run; baseline refreshed daily. | Steps-to-Win SLI | Compares agent win lengths against a random/baseline policy. | avg(env_steps_to_win_agent) / baseline <= 0.85. | Prometheus | Steps to Win | Metric | Histogram | `env_steps_to_win` | Histogram of environment steps consumed before a win. | `run_id`,`policy` | One observation per winning episode per policy. | Y | avg_over_time(env_steps_to_win{policy="agent",run_id="$run"}[1000episodes]) / max(env_steps_to_win{policy="random_baseline"}) <= 0.85 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | environment | src/battleship/ai/environment.py | Planned |
| Learning Progress | SLO-LRN-003 | Steps-to-Outcome | Avg steps to win ≤ 0.85 × baseline and steps-to-loss must be non-increasing over the last 1,000 episodes. | Sliding 1,000-episode cohorts per run. | Steps-to-Loss SLI | Ensures losing episodes do not simply drag out (stalling). | deriv(avg(env_steps_to_loss[1000 episodes])) <= 0. | Prometheus | Steps to Loss | Metric | Histogram | `env_steps_to_loss` | Histogram of environment steps consumed before a loss or truncation. | `run_id`,`policy` | One observation per losing episode per policy. | Y | deriv(avg_over_time(env_steps_to_loss{policy="agent",run_id="$run"}[1000episodes])) <= 0 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | environment | src/battleship/ai/environment.py | Planned |
| Agent Performance | SLO-AGT-002 | Invalid Moves / State Errors | Agent invalid actions ≤ 1 per 10,000 actions in any run. | Rolling 10k-action windows once exploration stabilises. | Agent Invalid Action SLI | Counts invalid actions emitted by the policy before the environment rejects them. | agent_invalid_action_total / total_actions <= 0.0001. | Prometheus | Agent Invalid Action Counter | Metric | Counter | `agent_invalid_action_total` | Counter incremented whenever the policy emits an invalid move. | `run_id`,`mode` | Low; increments only on violations. | Y | increase(agent_invalid_action_total{run_id="$run"}[10kactions]) <= 1 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | agent | src/battleship/ai/instrumented_agent.py | Planned |
| Training Stability | SLO-STAB-001 | Loss Trend & Variance | ≤0.5% NaN/Inf loss samples per 1,000 steps. | Rolling 1,000-step or 1,000-episode windows per run. | Loss Sample Health SLI | Counts invalid loss samples to compute the invalid rate. | training_loss_invalid_total / training_loss_samples_total <= 0.005. | Prometheus | Invalid Loss Sample Counter | Metric | Counter | `training_loss_invalid_total` | Counts NaN/Inf loss samples emitted by the trainer. | `run_id` | Low; increments only on invalid events. | Y | increase(training_loss_invalid_total{run_id="$run"}[1000steps]) / increase(training_loss_samples_total{run_id="$run"}[1000steps]) <= 0.005 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Training Stability | SLO-STAB-002 | Gradient Norm | ≤0.1% exploding gradients and ≤5% vanishing gradients over rolling 5,000 steps. | Rolling 5,000-step windows once warm-up completes. | Gradient Explode Rate SLI | Counts gradient norm samples above the exploding threshold. | training_gradient_norm_exploding_total / training_gradient_norm_samples_total <= 0.001. | Prometheus | Gradient Exploding Counter | Metric | Counter | `training_gradient_norm_exploding_total` | Number of gradient samples exceeding N_exp. | `run_id`,`threshold` | Low; increments only on outliers. | Y | increase(training_gradient_norm_exploding_total{run_id="$run"}[5000steps]) / increase(training_gradient_norm_samples_total{run_id="$run"}[5000steps]) <= 0.001 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Training Stability | SLO-STAB-002 | Gradient Norm | ≤0.1% exploding gradients and ≤5% vanishing gradients over rolling 5,000 steps. | Rolling 5,000-step windows once warm-up completes. | Gradient Vanish Rate SLI | Counts gradient norm samples below the vanishing threshold. | training_gradient_norm_vanishing_total / training_gradient_norm_samples_total <= 0.05. | Prometheus | Gradient Vanishing Counter | Metric | Counter | `training_gradient_norm_vanishing_total` | Number of gradient samples below N_vanish. | `run_id`,`threshold` | Low; increments only on outliers. | Y | increase(training_gradient_norm_vanishing_total{run_id="$run"}[5000steps]) / increase(training_gradient_norm_samples_total{run_id="$run"}[5000steps]) <= 0.05 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Training Stability | SLO-STAB-003 | Target Network Sync | Time between syncs ≤ 2× configured interval and failed sync attempts = 0. | Evaluate continuously per run. | Target Sync Cadence SLI | Tracks the timestamp/step of the last successful target network sync. | time() - target_network_last_sync_timestamp <= 2 × sync_interval. | Prometheus | Target Network Last Sync | Metric | Gauge | `target_network_last_sync_timestamp` | Gauge storing timestamp or step of last sync. | `run_id` | One gauge per run. | Y | time() - target_network_last_sync_timestamp{run_id="$run"} <= 2 * target_network_sync_interval{run_id="$run"} | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Training Stability | SLO-STAB-003 | Target Network Sync | Time between syncs ≤ 2× configured interval and failed sync attempts = 0. | Evaluate continuously per run. | Target Sync Failure SLI | Counts failed sync attempts (should stay at zero). | target_network_sync_failure_total == 0. | Prometheus | Target Network Sync Failures | Metric | Counter | `target_network_sync_failure_total` | Counter for failed target network sync attempts. | `run_id` | Low; increments only on failures. | Y | increase(target_network_sync_failure_total{run_id="$run"}[run]) == 0 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | trainer | src/battleship/ai/training.py | Planned |
| Exploration / Policy | SLO-EXP-001 | Epsilon Decay Health | Actual epsilon stays within ±10% of planned values in ≥99% of samples. | Evaluate every logged sample. | Epsilon Out-of-Band Counter | Counts samples outside the ±10% tolerance band. | epsilon_out_of_band_total == 0 for steady-state runs. | Prometheus | Epsilon Out-of-Band Counter | Metric | Counter | `epsilon_out_of_band_total` | Incremented whenever a sample deviates by more than ±10% from theoretical epsilon. | `run_id` | Low; increments only on deviation. | Y | increase(epsilon_out_of_band_total{run_id="$run"}[run]) == 0 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | agent | src/battleship/ai/instrumented_agent.py | Planned |
| Exploration / Policy | SLO-EXP-002 | Policy Entropy | Entropy stays above H_min_start early and tapers without collapsing. | Evaluate 0–25% and 50–100% episode segments. | Policy Entropy SLI | Tracks average entropy per training phase. | avg_entropy_phase1 >= H_min_start and avg_entropy_phase4 in [0.2×H_min_start, H_min_start). | Prometheus | Policy Entropy Gauge | Metric | Gauge | `agent_policy_entropy` | Average policy entropy recorded per episode with phase labels. | `run_id`,`phase` | One sample per episode per phase bucket. | Y | avg_over_time(agent_policy_entropy{phase="early",run_id="$run"}[0.25run]) >= H_min_start and avg_over_time(agent_policy_entropy{phase="late",run_id="$run"}[0.5run]) >= 0.2 * H_min_start | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | agent | src/battleship/ai/instrumented_agent.py | Planned |
| Exploration / Policy | SLO-EXP-002 | Policy Entropy | Entropy stays above H_min_start early and tapers without collapsing. | Evaluate designated episode ranges per run. | Entropy Floor Breach Counter | Counts samples outside the desired entropy band. | agent_policy_entropy_floor_breach_total == 0. | Prometheus | Policy Entropy Breach Counter | Metric | Counter | `agent_policy_entropy_floor_breach_total` | Incremented when entropy falls below floor early or stays too high late. | `run_id`,`phase` | Low; increments only on violations. | Y | increase(agent_policy_entropy_floor_breach_total{run_id="$run"}[run]) == 0 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | agent | src/battleship/ai/instrumented_agent.py | Planned |
| Observability Pipeline | SLO-OBS-001 | Telemetry Drop Rate | Dropped spans < 0.1% of processed spans over any 1-hour window. | Sliding 1-hour windows; two consecutive breaches trigger incident. | Span Drop Rate SLI | Percentage of spans dropped vs exported within the window. | dropped_spans / (dropped_spans + exported_spans) <= 0.001. | Prometheus | Dropped Spans Counter | Metric | Counter | `otelcol_dropped_spans_total` | Collector counter for spans dropped by the pipeline. | `pipeline`,`exporter` | Low; one counter per pipeline/exporter. | Y | sum(increase(otelcol_dropped_spans_total[1h])) / (sum(increase(otelcol_dropped_spans_total[1h])) + sum(increase(otelcol_exported_spans_total[1h]))) <= 0.001 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | collector | ops/otelcol/config.yaml | Planned |
| Observability Pipeline | SLO-OBS-001 | Telemetry Drop Rate | Dropped metrics < 0.1% of processed metrics over any 1-hour window. | Sliding 1-hour windows. | Metric Drop Rate SLI | Percentage of metrics dropped vs exported within the window. | dropped_metrics / (dropped_metrics + exported_metrics) <= 0.001. | Prometheus | Dropped Metrics Counter | Metric | Counter | `otelcol_dropped_metrics_total` | Collector counter for metric points dropped by the pipeline. | `pipeline`,`exporter` | Low; one counter per pipeline/exporter. | Y | sum(increase(otelcol_dropped_metrics_total[1h])) / (sum(increase(otelcol_dropped_metrics_total[1h])) + sum(increase(otelcol_exported_metrics_total[1h]))) <= 0.001 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | collector | ops/otelcol/config.yaml | Planned |
| Observability Pipeline | SLO-OBS-002 | Exporter Reliability | ≤1 exporter failure per pipeline in any 15-minute window and no failure burst >3 minutes. | Sliding 15-minute windows; consecutive failures limited to 3 minutes. | Span Export Failure SLI | Counts OTLP exporter send failures for span pipelines. | increase(otelcol_exporter_send_failed_spans_total[15m]) <= 1. | Prometheus | Span Export Failures | Metric | Counter | `otelcol_exporter_send_failed_spans_total` | Counter of OTLP exporter failures for span data. | `pipeline`,`exporter` | Low; increments per failure event. | Y | increase(otelcol_exporter_send_failed_spans_total[15m]) <= 1 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | collector | ops/otelcol/config.yaml | Planned |
| Observability Pipeline | SLO-OBS-002 | Exporter Reliability | ≤1 exporter failure per pipeline in any 15-minute window and no failure burst >3 minutes. | Sliding 15-minute windows. | Metric Export Failure SLI | Counts OTLP exporter send failures for metric pipelines. | increase(otelcol_exporter_send_failed_metrics_total[15m]) <= 1. | Prometheus | Metric Export Failures | Metric | Counter | `otelcol_exporter_send_failed_metrics_total` | Counter of OTLP exporter failures for metrics. | `pipeline`,`exporter` | Low; increments per failure event. | Y | increase(otelcol_exporter_send_failed_metrics_total[15m]) <= 1 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | collector | ops/otelcol/config.yaml | Planned |
| Observability Pipeline | SLO-OBS-003 | Collector Queue Pressure | p95 queue pressure ≤ 0.5 and p99 ≤ 0.7 over any 30-minute period. | Rolling 30-minute windows per pipeline. | Queue Pressure SLI | Measures collector send queue utilization. | quantile(queue_pressure,0.95) <= 0.5 AND quantile(queue_pressure,0.99) <= 0.7. | Prometheus | Collector Queue Pressure | Metric | Gauge | `otelcol_queue_pressure_ratio` | Gauge reported by the collector for queue occupancy. | `pipeline` | Low; one gauge per pipeline. | Y | quantile_over_time(0.95, otelcol_queue_pressure_ratio[30m]) <= 0.5 and quantile_over_time(0.99, otelcol_queue_pressure_ratio[30m]) <= 0.7 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | collector | ops/otelcol/config.yaml | Planned |
| Environment / Engine Integrity | SLO-ENV-001 | Placement Success Rate | Placement success rate ≥ 99.9% (≤0.1% failures) per run. | Evaluated per run with alerts on sustained deviation. | Placement Success SLI | Counts successful placement completions used in the success-rate ratio. | success / (success + failure) ≥ 0.999. | Prometheus | Placement Success Counter | Metric | Counter | `env_placement_success_total` | Counts episodes where placement completed without errors. | `run_id`,`actor` | Low; increments per successful placement. | Y | sum(increase(env_placement_success_total{run_id="$run"}[run])) / (sum(increase(env_placement_success_total{run_id="$run"}[run])) + sum(increase(env_placement_failures_total{run_id="$run"}[run]))) >= 0.999 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | environment | src/battleship/ai/environment.py | Planned |
| Environment / Engine Integrity | SLO-ENV-001 | Placement Success Rate | Placement success rate ≥ 99.9% (≤0.1% failures) per run. | Evaluated per run. | Placement Failure SLI | Counts failed placement attempts to confirm the error budget. | env_placement_failures_total <= 0.001 × total placements. | Prometheus | Placement Failure Counter | Metric | Counter | `env_placement_failures_total` | Counts placement failures (should stay near zero). | `run_id`,`actor` | Low; increments only when placement fails. | Y | increase(env_placement_failures_total{run_id="$run"}[run]) <= 0.001 * increase(env_placement_success_total{run_id="$run"}[run]) | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | environment | src/battleship/ai/environment.py | Planned |
| Environment / Engine Integrity | SLO-ENV-002 | Engine Step Stability | Engine step error rate ≤ 1e-5 errors per step and engine exceptions = 0. | Evaluated per run and rolling windows. | Environment Step Error SLI | Counts environment step errors relative to steps taken. | env_step_error_total / env_step_total <= 1e-5. | Prometheus | Environment Step Errors | Metric | Counter | `env_step_error_total` | Counts errors thrown during env.step processing. | `run_id` | Low; increments only on errors. | Y | increase(env_step_error_total{run_id="$run"}[run]) / increase(battleship_env_actions_total{run_id="$run"}[run]) <= 1e-5 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | environment | src/battleship/ai/environment.py | Planned |
| Environment / Engine Integrity | SLO-ENV-002 | Engine Step Stability | Engine step error rate ≤ 1e-5 errors per step and engine exceptions = 0. | Evaluated per run. | Engine Exception SLI | Counts exceptions thrown by the game engine. | engine_exceptions_total == 0. | Prometheus | Engine Exceptions Counter | Metric | Counter | `engine_exceptions_total` | Counts fatal exceptions thrown by the engine. | `run_id` | Should remain zero. | Y | increase(engine_exceptions_total{run_id="$run"}[run]) == 0 | – | – | – | – | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | engine | src/battleship/engine/instrumented_game.py | Planned |
| – | – | – | – | – | – | – | – | Prometheus | Game Setups Completed | Metric | Counter | `battleship_game_setup_total` | Counts randomized game setup executions | `player1_ships`,`player2_ships` |  | Y | `sum(rate(battleship_game_setup_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Ship Placements Attempted | Metric | Counter | `battleship_engine_ship_placements` | Counts ship placement attempts and results | `result`,`owner` |  | Y | `sum by (result) (rate(battleship_engine_ship_placements[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Games Completed | Metric | Counter | `battleship_game_completed_total` | Increments when a game reaches a terminal winner | `winner` |  | Y | `sum by (winner) (increase(battleship_game_completed_total[1h]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Game Duration Seconds | Metric | Histogram | `battleship_game_duration_seconds` | Measures setup→finish duration per game | `winner` |  | Y | `histogram_quantile(0.9, sum by (le) (rate(battleship_game_duration_seconds_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Engine Shots Registered | Metric | Counter | `battleship_engine_shots` | Counts board shots labelled by hit/miss | `outcome`,`owner` |  | Y | `sum by (outcome) (rate(battleship_engine_shots[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Engine Moves Processed | Metric | Counter | `battleship_engine_moves` | Counts validated moves taken in BattleshipGame | `result`,`player` |  | Y | `sum by (player) (rate(battleship_engine_moves[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Engine Game | `src/battleship/engine/game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Shots Issued | Metric | Counter | `battleship_shots_total` | Counts every move/shot taken | `player` |  | Y | `sum by (player) (rate(battleship_shots_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Shots by Result | Metric | Counter | `battleship_shots_by_result_total` | Counts shots broken down by hit/miss | `player`,`result` |  | Y | `sum by (result) (rate(battleship_shots_by_result_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Invalid Game Moves | Metric | Counter | `battleship_game_invalid_moves_total` | Tracks invalid move attempts rejected by the engine | `player`,`reason` |  | Y | `increase(battleship_game_invalid_moves_total[1h])` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Environment Resets | Metric | Counter | `battleship_env_reset_total` | Counts Gym resets | – |  | Y | `rate(battleship_env_reset_total[5m])` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Environment Reset Latency | Metric | Histogram | `battleship_env_reset_latency_ms` | Measures reset runtime in milliseconds | – |  | Y | `histogram_quantile(0.95, sum by (le) (rate(battleship_env_reset_latency_ms_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Environment Actions | Metric | Counter | `battleship_env_actions_total` | Counts placement/firing actions processed | `phase`,`result` |  | Y | `sum by (phase) (rate(battleship_env_actions_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Environment Step Latency | Metric | Histogram | `battleship_env_step_latency_ms` | Measures `step` call latency | `phase` |  | Y | `histogram_quantile(0.9, sum by (phase, le) (rate(battleship_env_step_latency_ms_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Environment Rewards | Metric | Counter | `battleship_env_rewards_total` | Tallies positive/zero reward magnitudes | `phase`,`type` |  | Y | `sum by (type) (rate(battleship_env_rewards_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Negative Environment Rewards | Metric | Counter | `battleship_env_negative_rewards_total` | Tracks absolute magnitude of negative rewards | `phase`,`type` |  | Y | `sum(rate(battleship_env_negative_rewards_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| Agent Performance | SLO-AGT-001 | Hit/Miss Accuracy | Hit rate ≥ 45% over the last 1,000 episodes of any training run. | Sliding 1,000-episode window after warm-up; 55% miss budget. | Hit Accuracy SLI (Hits) | Counts successful shots for the hit-rate numerator. | hits / (hits + misses) over the last 1,000 episodes. | Prometheus | Environment Hits | Metric | Counter | `battleship_env_hits_total` | Counts hits registered by the environment | `phase` | One counter increment per shot outcome grouped by phase. | Y | sum_over_time(battleship_env_hits_total{run_id="$run"}[1000episodes]) / (sum_over_time(battleship_env_hits_total{run_id="$run"}[1000episodes]) + sum_over_time(battleship_env_misses_total{run_id="$run"}[1000episodes])) | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | Implemented |
| Agent Performance | SLO-AGT-001 | Hit/Miss Accuracy | Hit rate ≥ 45% over the last 1,000 episodes of any training run. | Sliding 1,000-episode window after warm-up; 55% miss budget. | Hit Accuracy SLI (Misses) | Counts misses so the denominator stays accurate. | hits / (hits + misses) over the last 1,000 episodes. | Prometheus | Environment Misses | Metric | Counter | `battleship_env_misses_total` | Counts misses registered by the environment | `phase` | One counter increment per shot outcome grouped by phase. | Y | sum_over_time(battleship_env_hits_total{run_id="$run"}[1000episodes]) / (sum_over_time(battleship_env_hits_total{run_id="$run"}[1000episodes]) + sum_over_time(battleship_env_misses_total{run_id="$run"}[1000episodes])) | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | Implemented |
| Agent Performance | SLO-AGT-002 | Invalid Moves / State Errors | Environment state violations must be 0 per run; invalid agent actions ≤ 1 per 10,000 actions. | Evaluate per run or rolling 10k-action buckets; zero tolerance for env state breaks. | Environment Invalid Transition SLI | Counts invalid placement/firing attempts rejected by the environment. | env_invalid_state_transition_total == 0. | Prometheus | Environment Invalid Actions | Metric | Counter | `battleship_env_invalid_actions_total` | Counts invalid placement/firing attempts | `phase` | Incremented whenever gym invariants reject an action. | Y | increase(battleship_env_invalid_actions_total{run_id="$run"}[run]) == 0 | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | Implemented |
| – | – | – | – | – | – | – | – | Prometheus | Environment Placements Completed | Metric | Counter | `battleship_env_placement_complete_total` | Counts when player placement phase successfully completes | – |  | Y | `increase(battleship_env_placement_complete_total[1h])` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Environment Episodes Completed | Metric | Counter | `battleship_env_episode_completed_total` | Increments when episodes terminate/truncate | `result` |  | Y | `sum by (result) (rate(battleship_env_episode_completed_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Agent Actions | Metric | Counter | `battleship_agent_actions_total` | Counts actions chosen by the DQN agent | `mode` |  | Y | `sum by (mode) (rate(battleship_agent_actions_total[5m]))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Agent Action Latency | Metric | Histogram | `battleship_agent_action_latency_ms` | Measures latency of `select_action` | `mode` |  | Y | `histogram_quantile(0.9, sum by (mode, le) (rate(battleship_agent_action_latency_ms_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| Exploration / Policy | SLO-EXP-001 | Epsilon Decay Health | Actual epsilon stays within ±10% of planned values and reaches its minimum before 80% of planned episodes. | Evaluate at every logged episode; ≥99% of samples must stay within bounds. | Epsilon Schedule SLI | Compares the live epsilon gauge to the theoretical decay schedule. | abs(epsilon_actual - epsilon_planned)/epsilon_planned <= 0.10 and min_reached_episode <= 0.80 × total_episodes. | Prometheus | Agent Epsilon Value | Metric | Counter | `battleship_agent_epsilon` | Writes current exploration epsilon | – | One sample per episode per run. | Y | max_over_time(epsilon_out_of_band{run_id="$run"}[run]) == 0 and last_over_time(agent_epsilon_min_reached_episode{run_id="$run"}[1h]) <= 0.80 * total_planned_episodes{run_id="$run"} | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | Implemented |
| – | – | – | – | – | – | – | – | Prometheus | Agent Training Steps | Metric | Counter | `battleship_agent_training_steps_total` | Counts training step executions | – |  | Y | `rate(battleship_agent_training_steps_total[5m])` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Agent Training Latency | Metric | Histogram | `battleship_agent_training_latency_ms` | Measures training loop latency | – |  | Y | `histogram_quantile(0.9, sum by (le) (rate(battleship_agent_training_latency_ms_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| Training Stability | SLO-STAB-001 | Loss Trend & Variance | ≤0.5% NaN/Inf loss samples and stddev ≤ 3× baseline over any 1,000-episode window. | Monitor rolling 1,000-episode windows per run once warm-up completes. | Training Loss Stability SLI | Ensures scalar loss values remain finite and variance stays bounded. | invalid_rate <= 0.005 AND stddev(loss[1000 episodes]) <= 3 × baseline. | Prometheus | Agent Training Loss | Metric | Counter | `battleship_agent_training_loss` | Records loss value per training step | – | One sample per optimizer step grouped by run_id. | Y | stddev_over_time(battleship_agent_training_loss{run_id="$run"}[1000episodes]) <= 3 * loss_stddev_baseline{run_id="$run"} | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | Implemented |
| – | – | – | – | – | – | – | – | Prometheus | Episode Reward Histogram | Metric | Histogram | `battleship_episode_reward` | Records total reward per episode | – |  | Y | `histogram_quantile(0.5, sum by (le) (rate(battleship_episode_reward_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Episode Mean Loss | Metric | Histogram | `battleship_episode_mean_loss` | Records mean loss per episode | – |  | Y | `histogram_quantile(0.5, sum by (le) (rate(battleship_episode_mean_loss_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Prometheus | Evaluation Win Rate | Metric | Histogram | `battleship_eval_win_rate` | Records evaluation win rate after eval runs | – |  | Y | `histogram_quantile(0.5, sum by (le) (rate(battleship_eval_win_rate_bucket[5m])))` | N |  | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/metrics`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Board Ship Placement Span | Span | Span | `board.place_ship` | Wraps ship placement validation with OTEL span | `ship.type`,`ship.length`,`ship.start.row`,`ship.start.col`,`board.owner` |  | N |  | N |  | Y | `span.name = "board.place_ship"` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Board Receive Shot Span | Span | Span | `board.receive_shot` | Captures shot coordinates/outcome on target board | `shot.row`,`shot.col`,`board.owner`,`shot.outcome` |  | N |  | N |  | Y | `{ span.name = "board.receive_shot" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Board Random Placement Span | Span | Span | `board.random_placement` | Random fleet placement loop instrumentation | `board.owner` |  | N |  | N |  | Y | `{ span.name = "board.random_placement" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Engine Game Span | Span | Span | `battleship.engine.game` | Root span for each simulated match | `game.id`,`winner`,`turns`,`duration_ms` |  | N |  | N |  | Y | `{ span.name = "battleship.engine.game" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| Environment / Engine Integrity | SLO-ENV-003 | Episode Initialization Latency | p95 random setup latency ≤ 100 ms and p99 ≤ 250 ms. | Sliding 15-minute windows aligned with env.reset monitoring. | Engine Setup Latency SLI | Tempo span measuring random placement/setup time. | p95(setup_duration) <= 100ms AND p99 <= 250ms. | Tempo | Engine Setup Span | Span | Span | `battleship.engine.setup_random` | Records random setup sequence per game | `player1_ships`,`player2_ships` | One span per setup per game. | N |  | N |  | Y | service.name="battleship-engine" and span.name="battleship.engine.setup_random" | quantile(duration_ms, 0.95) < 100 and quantile(duration_ms, 0.99) < 250 | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | Implemented |
| – | – | – | – | – | – | – | – | Tempo | Engine Make Move Span | Span | Span | `battleship.engine.make_move` | Wraps each move with attributes for coords/player | `game.id`,`player`,`coord.row`,`coord.col`,`shot_outcome`,`hit`,`sunk` |  | N |  | N |  | Y | `{ span.name = "battleship.engine.make_move" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Engine Game Complete Span | Span | Span | `battleship.engine.game_complete` | Emits summary span at match completion | `game.id`,`winner`,`turns`,`duration_ms` |  | N |  | N |  | Y | `{ span.name = "battleship.engine.game_complete" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| Environment / Engine Integrity | SLO-ENV-003 | Episode Initialization Latency | p95 reset latency ≤ 100 ms and p99 ≤ 250 ms during training. | Sliding 15-minute windows covering active runs. | Env Reset Latency SLI | Tempo span recording reset latency and context. | p95(reset_duration) <= 100ms AND p99 <= 250ms. | Tempo | Environment Reset Span | Span | Span | `battleship.env.reset` | Tracks Gym reset context and latency | `episode_id`,`phase` | One span per env.reset per episode. | N |  | N |  | Y | service.name="battleship-env" and span.name="battleship.env.reset" | quantile(duration_ms, 0.95) < 100 and quantile(duration_ms, 0.99) < 250 | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | Implemented |
| – | – | – | – | – | – | – | – | Tempo | Environment Step Span | Span | Span | `battleship.env.step` | Records step actions, rewards, invalid states | `episode_id`,`phase`,`action_index`,`reward_type`,`terminated`,`truncated` |  | N |  | N |  | Y | `{ span.name = "battleship.env.step" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| Exploration / Policy | SLO-EXP-003 | Action Latency | p95 agent.select_action latency ≤ 50 ms and p99 ≤ 100 ms. | Sliding 15-minute windows; trigger after two consecutive violations. | Agent Action Latency SLI | Tempo span capturing per-action inference latency. | p95 <= 50ms AND p99 <= 100ms. | Tempo | Agent Select Action Span | Span | Span | `battleship.agent.select_action` | Captures agent policy selection metadata | `epsilon`,`exploratory`,`action` | One span per action decision labelled with epsilon/action. | N |  | N |  | Y | service.name="battleship-agent" and span.name="battleship.agent.select_action" | quantile(duration_ms, 0.95) < 50 and quantile(duration_ms, 0.99) < 100 | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | Implemented |
| – | – | – | – | – | – | – | – | Tempo | Agent Train Step Span | Span | Span | `battleship.agent.train_step` | Wraps replay buffer training iterations | `buffer_size`,`batch_size`,`loss` |  | N |  | N |  | Y | `{ span.name = "battleship.agent.train_step" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Train Episode Span | Span | Span | `train_episode` | Per-episode span covering rollout metrics | `episode`,`reward`,`steps`,`mean_loss` |  | N |  | N |  | Y | `span.service.name = "battleship-trainer" and span.name = "train_episode"` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Evaluate Agent Span | Span | Span | `evaluate_agent` | Evaluation span summarising win rate stats | `mean_reward`,`win_rate`,`avg_length` |  | N |  | N |  | Y | `span.name = "evaluate_agent"` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Tempo | Pipeline Phase Span | Span | Span | `pipeline.phase` | High-level span for each adaptive training phase | `phase`,`epoch` |  | N |  | N |  | Y | `{ span.name = "pipeline.phase" }` | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/traces`) | `otelcol.receiver.otlp.default` | Training Pipeline | `scripts/auto_train_pipeline.py` | active |
| – | – | – | – | – | – | – | – | Loki | Ship Placement Failed Log | Log | Structured Log | `ship_placement_failed` | Warning log when placement violates rules | `owner`,`ship_type`,`orientation`,`row`,`col` |  | N |  | Y | `{app=\"battleship\"} |= \"ship_placement_failed\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Loki | Ship Placed Log | Log | Structured Log | `ship_placed` | Info log emitted after successful placement | `owner`,`ship_type`,`orientation`,`row`,`col` |  | N |  | Y | `{app=\"battleship\"} |= \"ship_placed\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Loki | Shot Outcome Logs | Log | Structured Log | `shot_hit` / `shot_miss` / `shot_out_of_bounds` / `shot_duplicate` | Logs for hit/miss/errors when shots applied | `row`,`col`,`owner`,`ship_type` |  | N |  | Y | `{app=\"battleship\"} |= \"shot_hit\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Loki | Random Ship Placement Debug | Log | Structured Log | `random_ship_placed` | Debug log for random placement attempts | `ship_type`,`attempts`,`owner` |  | N |  | Y | `{app=\"battleship\"} |= \"random_ship_placed\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Engine Board | `src/battleship/engine/board.py` | active |
| – | – | – | – | – | – | – | – | Loki | Game Move Logs | Log | Structured Log | `make_move ... outcome` | Info log summarizing move actions/outcomes | `player`,`coord.row`,`coord.col`,`outcome` |  | N |  | Y | `{app=\"battleship.engine\"} |= \"make_move\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Loki | Game Finished Log | Log | Structured Log | `game_finished` | Info log when a match ends with winner stats | `winner`,`turns`,`duration_s` |  | N |  | Y | `{app=\"battleship.engine\"} |= \"Game finished\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Instrumented Game | `src/battleship/engine/instrumented_game.py` | active |
| – | – | – | – | – | – | – | – | Loki | Environment Reset Log | Log | Structured Log | `env_reset` | Info log when env reset occurs | `phase`,`allow_agent_placement`,`allow_opponent_placement` |  | N |  | Y | `{app=\"battleship.env\"} |= \"env_reset\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Loki | Invalid Action Log | Log | Structured Log | `invalid_action` | Warning log when invalid placement/firing occurs | `phase`,`reason`,`actor`,`ship_type` |  | N |  | Y | `{app=\"battleship.env\"} |= \"invalid_action\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Loki | Player Placement Complete Log | Log | Structured Log | `player_placement_complete` | Info log when agent finishes placement | `actor` |  | N |  | Y | `{app=\"battleship.env\"} |= \"player_placement_complete\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Loki | Opponent Placement Logs | Log | Structured Log | `opponent_manual_placement_*` | Info logs when manual opponent placement occurs | `actor`,`phase` |  | N |  | Y | `{app=\"battleship.env\"} |= \"opponent_manual_placement\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Loki | Environment Phase Transition Log | Log | Structured Log | `env_phase_transition` | Info log when environment switches phases | `phase` |  | N |  | Y | `{app=\"battleship.env\"} |= \"env_phase_transition\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | BattleshipEnv | `src/battleship/ai/environment.py` | active |
| – | – | – | – | – | – | – | – | Loki | Trainer Initialised Log | Log | Structured Log | `trainer_initialised` | Info log when trainer boots with config summary | `episodes`,`save_dir`,`opponent` |  | N |  | Y | `{app=\"battleship.ai\"} |= \"trainer_initialised\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Loki | Train Episode Log | Log | Structured Log | `train_episode` | Info log emitted per training episode | `episode`,`reward`,`steps`,`mean_loss`,`epsilon` |  | N |  | Y | `{app=\"battleship.ai\"} |= \"train_episode\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Loki | Evaluate Agent Log | Log | Structured Log | `evaluate_agent` | Info log after evaluation summarizing metrics | `mean_reward`,`win_rate`,`avg_length` |  | N |  | Y | `{app=\"battleship.ai\"} |= \"evaluate_agent\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Trainer | `src/battleship/ai/training.py` | active |
| – | – | – | – | – | – | – | – | Loki | Pipeline Phase Logs | Log | Structured Log | `phase_start` / `phase_episode` / `phase_epoch_eval` / `phase_criteria_met` | Structured logs for adaptive phase telemetry | `phase`,`episode`,`epoch`,`win_rate`,`opponent` |  | N |  | Y | `{app=\"battleship.pipeline\"} |= \"phase_start\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Training Pipeline | `scripts/auto_train_pipeline.py` | active |
| – | – | – | – | – | – | – | – | Loki | Agent Action Log | Log | Structured Log | `select_action ...` | Info log emitted during action selection with epsilon context | `epsilon`,`action`,`exploratory` |  | N |  | Y | `{app=\"battleship.agent\"} |= \"select_action\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| – | – | – | – | – | – | – | – | Loki | Agent Train Step Log | Log | Structured Log | `train_step ...` | Info log recording loss values from training | `loss` |  | N |  | Y | `{app=\"battleship.agent\"} |= \"train_step\"` | N |  | `OTEL_EXPORTER_OTLP_ENDPOINT` (`v1/logs`) | `otelcol.receiver.otlp.default` | Instrumented Agent | `src/battleship/ai/instrumented_agent.py` | active |
| – | – | – | – | – | – | – | – | – | Game Sessions Started | Metric | Counter | `battleship_game_started_total` | Planned counter for game start events (not emitted) | – |  | N |  | N |  | N |  | – (not implemented) | – | Instrumented Game | `TODO.md` | deprecated |
| – | – | – | – | – | – | – | – | – | Agent Inference Duration | Metric | Histogram | `battleship_agent_inference_duration_seconds` | Planned histogram for `select_action` duration in seconds | – |  | N |  | N |  | N |  | – (not implemented) | – | Instrumented Agent | `TODO.md` | deprecated |
| – | – | – | – | – | – | – | – | – | Agent Training Step Duration | Metric | Histogram | `battleship_agent_training_step_duration_seconds` | Planned histogram for per-step training duration | – |  | N |  | N |  | N |  | – (not implemented) | – | Instrumented Agent | `TODO.md` | deprecated |
| – | – | – | – | – | – | – | – | – | Environment Resets Total (legacy) | Metric | Counter | `battleship_env_resets_total` | Early naming for reset counter (superseded by `battleship_env_reset_total`) | – |  | N |  | N |  | N |  | – (not implemented) | – | BattleshipEnv | `TODO.md` | deprecated |
| – | – | – | – | – | – | – | – | – | Environment Step Duration Seconds | Metric | Histogram | `battleship_env_step_duration_seconds` | Planned histogram for env step duration in seconds | – |  | N |  | N |  | N |  | – (not implemented) | – | BattleshipEnv | `TODO.md` | deprecated |
| – | – | – | – | – | – | – | – | – | Environment Reward Value | Metric | Histogram | `battleship_env_reward_value` | Optional histogram proposal for raw reward magnitude | – |  | N |  | N |  | N |  | – (not implemented) | – | BattleshipEnv | `TODO.md` | deprecated |
